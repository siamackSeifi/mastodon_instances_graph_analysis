import networkx as nx
from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score
import igraph as ig
from collections import defaultdict
import community.community_louvain as community_louvain
import leidenalg as la
from networkx.algorithms.community.quality import modularity
import matplotlib.pyplot as plt
import random
from networkx.algorithms.community import girvan_newman, label_propagation_communities
import itertools
import hashlib

# Load unweighted edgelist
def load_unweighted_graph(file_path):
    G = nx.read_edgelist(file_path, delimiter=' ')
    return G

# Load weighted edgelist
def load_weighted_graph(file_path):
    G = nx.Graph()
    with open(file_path, 'r') as file:
        for line in file:
            parts = line.strip().split()
            if len(parts) == 3:
                u, v, weight = parts[0], parts[1], float(parts[2])
                weight = max(weight, 0)  # Set negative weights to 0
                G.add_edge(u, v, weight=weight)
            else:
                raise ValueError(f"Invalid line in file: {line}")
    return G

# Detect communities using Louvain algorithm
def detect_louvain_communities(graph, is_weighted=False):
    if is_weighted:
      partition = community_louvain.best_partition(graph, weight='weight')
    else:
      partition = community_louvain.best_partition(graph)
    return partition

# Detect communities using Leiden algorithm (igraph)
def detect_leiden_communities(graph, is_weighted=False):
    g = ig.Graph.from_networkx(graph)
    
    # Extract weights if the graph is weighted
    weights = g.es["weight"] if is_weighted and "weight" in g.es.attributes() else None

    # Run the Leiden algorithm
    partition = la.find_partition(g, la.ModularityVertexPartition, weights=weights)

    # Create a dictionary mapping nodes to their community labels
    node_to_community = {node: community for node, community in zip(graph.nodes(), partition.membership)}

    return node_to_community

def detect_label_propagation_communities(graph):
    communities = label_propagation_communities(graph)

    # Map nodes to their community labels
    node_to_community = {node: idx for idx, community in enumerate(communities) for node in community}

    return node_to_community

def girvan_newman_best_partition(graph, max_splits=None):
    """
    Perform the Girvan-Newman algorithm and return the best partition based on modularity.

    Parameters:
        graph (networkx.Graph): The input graph.
        max_splits (int or None): The maximum number of splits to perform. If None, will split until the graph is fully divided.

    Returns:
        dict: A dictionary mapping nodes to their community labels.
        float: The modularity score of the best partition.
    """
    # Generate communities using Girvan-Newman
    comp = girvan_newman(graph)
    
    # Initialize variables to store the best partition and modularity score
    best_partition = None
    best_modularity = -1  # Modularity score typically ranges from -1 to 1
    
    # Iterate over partitions generated by the algorithm
    for communities in itertools.islice(comp, max_splits):
        partition = [set(c) for c in communities]
        
        # Calculate modularity for this partition
        mod_score = modularity(graph, partition)
        
        # Update best partition if this partition has higher modularity
        if mod_score > best_modularity:
            best_modularity = mod_score
            best_partition = partition
    
    # Create a dictionary of node to community label
    node_to_community = {}
    for community_label, community in enumerate(best_partition):
        for node in community:
            node_to_community[node] = community_label
    
    return node_to_community, best_modularity


# Calculate modularity
def calculate_modularity(graph, partition):
    communities = defaultdict(list)
    for node, community in partition.items():
        communities[community].append(node)
    community_list = list(communities.values())
    return modularity(graph, community_list)

# Calculate ARI and NMI between two partitions
def calculate_partition_similarity(partition1, partition2):
    labels1 = list(partition1.values())
    labels2 = list(partition2.values())
    ari = adjusted_rand_score(labels1, labels2)
    nmi = normalized_mutual_info_score(labels1, labels2)
    return ari, nmi

# Number of partitions
def calculate_number_of_communities(partition):
    return len(set(partition.values()))

# Community sizes
def calculate_community_sizes(partition):
    from collections import Counter
    sizes = Counter(partition.values())
    return sizes

def visualize_communities(graph, partition, title, output_file, node_size=20):
    # Define a set of maximally distinctive colors
    distinct_colors = ["#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00"]  # Red, Blue, Green, Orange
    
    # Get unique communities and sort them
    communities = sorted(set(partition.values()))
    num_communities = len(communities)

    # Ensure we have enough colors (limit to 4)
    if num_communities > len(distinct_colors):
        raise ValueError(f"Too many communities ({num_communities})! Max supported is {len(distinct_colors)}.")

    # Assign colors to communities
    color_map = {community: distinct_colors[i] for i, community in enumerate(communities)}
    
    # Assign colors to nodes
    node_colors = [color_map[partition[node]] for node in graph.nodes()]

    # Plot the graph
    plt.figure(figsize=(12, 12))
    # pos = nx.spring_layout(graph, seed=42)  # Spring layout for visualization
    pos = nx.spring_layout(graph, k=0.15, seed=100)

    nx.draw_networkx_nodes(graph, pos, node_color=node_colors, node_size=node_size)
    nx.draw_networkx_edges(graph, pos, alpha=0.2, width=0.3, edge_color="gray")

    # Create a legend
    legend_handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color_map[community], markersize=10)
                      for community in communities]
    plt.legend(legend_handles, [f"Community {c}" for c in communities],
               title="Communities", loc="upper right", fontsize='small', title_fontsize='medium')

    # plt.title(title, fontsize=16)
    plt.axis('off')
    plt.savefig(f"visualizations/with_seed/{output_file}", format='png', dpi=300, bbox_inches='tight')
    plt.close()

def visualize_communities_based_on_hash(graph, partition, title, output_file, node_size=20):
    # Fixed color palette (Red, Blue, Green, Orange)
    distinct_colors = ["#E41A1C", "#377EB8", "#4DAF4A", "#FF7F00"]

    # Group nodes by community
    community_to_nodes = defaultdict(list)
    for node, community_id in partition.items():
        community_to_nodes[community_id].append(node)

    # Use sorted node lists to uniquely identify communities
    community_signatures = []
    for community_nodes in community_to_nodes.values():
        signature = tuple(sorted(community_nodes))
        community_signatures.append(signature)

    # Sort communities deterministically by their signature
    community_signatures.sort()

    # Map each community signature to a fixed color
    if len(community_signatures) > len(distinct_colors):
        raise ValueError(f"Too many communities ({len(community_signatures)})! Max supported is {len(distinct_colors)}.")
    
    signature_to_color = {
        signature: distinct_colors[i]
        for i, signature in enumerate(community_signatures)
    }

    # Create a mapping from original community ID to color
    community_id_to_color = {}
    for community_id, nodes in community_to_nodes.items():
        signature = tuple(sorted(nodes))
        community_id_to_color[community_id] = signature_to_color[signature]

    # Assign colors to each node
    node_colors = [community_id_to_color[partition[node]] for node in graph.nodes()]

    # Plot the graph
    plt.figure(figsize=(12, 12))
    pos = nx.spring_layout(graph, k=0.15, seed=100)

    nx.draw_networkx_nodes(graph, pos, node_color=node_colors, node_size=node_size)
    nx.draw_networkx_edges(graph, pos, alpha=0.2, width=0.3, edge_color="gray")

    # Legend (optional)
    legend_handles = [
        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10)
        for color in distinct_colors[:len(community_signatures)]
    ]
    plt.legend(
        legend_handles,
        [f"Community {i}" for i in range(len(community_signatures))],
        title="Communities",
        loc="upper right",
        fontsize='small',
        title_fontsize='medium'
    )

    plt.axis('off')
    plt.savefig(f"visualizations/with_seed_and_hash/{output_file}", format='png', dpi=300, bbox_inches='tight')
    plt.close()



def calculate_modularity_density(graph, partition):
    """
    Calculate the Modularity Density (Qd) of a partition.

    Parameters:
        graph: NetworkX graph.
        partition: Dictionary mapping nodes to community labels.

    Returns:
        Modularity density (float).
    """
    # Group nodes by community
    communities = defaultdict(list)
    for node, community in partition.items():
        communities[community].append(node)

    m = graph.size(weight='weight')  # Total edge weight
    modularity_density = 0

    for community_nodes in communities.values():
        # Subgraph for the current community
        subgraph = graph.subgraph(community_nodes)
        e_c = subgraph.size(weight='weight')  # Internal edge weight
        a_c = sum(dict(graph.degree(community_nodes, weight='weight')).values()) / (2 * m)

        if a_c > 0:  # Avoid division by zero
            modularity_density += e_c / m - a_c ** 2 + (e_c / a_c)

    return modularity_density

def calculate_conductance(graph, partition):
    """
    Calculate the conductance for each community in a graph partition.

    Parameters:
        graph: NetworkX graph.
        partition: Dictionary mapping nodes to community labels.

    Returns:
        Dictionary of conductance values for each community.
    """
    # Group nodes by community
    communities = defaultdict(list)
    for node, community in partition.items():
        communities[community].append(node)

    conductance_scores = {}
    for community_label, community_nodes in communities.items():
        # Subgraph for the community
        subgraph = graph.subgraph(community_nodes)
        internal_edges = subgraph.size(weight='weight')  # Internal edge weight

        # Total degree of community nodes
        total_degree = sum(dict(graph.degree(community_nodes, weight='weight')).values())

        # Boundary edges (edges crossing the community boundary)
        boundary_edges = total_degree - 2 * internal_edges

        # Conductance calculation
        if total_degree > 0:
            conductance_scores[community_label] = boundary_edges / min(total_degree, graph.size(weight='weight') - total_degree)
        else:
            conductance_scores[community_label] = 0

    return conductance_scores
